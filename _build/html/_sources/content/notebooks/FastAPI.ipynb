{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained RidgeClassifier model\n",
    "model = joblib.load(\"ridge_feature_engineering_model.joblib\")\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Define the input schema for the POST request\n",
    "class PredictRequest(BaseModel):\n",
    "    Annual_Income: int\n",
    "    Family_Size: int\n",
    "    Age: int\n",
    "    Work_Experience: int\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: PredictRequest):\n",
    "    try:\n",
    "        # Parse input into a dictionary\n",
    "        input_dict = {\n",
    "            \"Annual_Income\": [data.Annual_Income],\n",
    "            \"Family_Size\": [data.Family_Size],\n",
    "            \"Age\": [data.Age],\n",
    "            \"Work_Experience\": [data.Work_Experience],\n",
    "            \"Income_Per_Family\": [data.Annual_Income / (data.Family_Size + 1)],  # Float value\n",
    "            \"Age_Experience_Interaction\": [data.Age * data.Work_Experience]\n",
    "        }\n",
    "\n",
    "        # Convert the dictionary into a Pandas DataFrame\n",
    "        input_df = pd.DataFrame(input_dict)\n",
    "\n",
    "        # Ensure the DataFrame column order matches the expected columns\n",
    "        expected_columns = [\n",
    "            \"Annual_Income\",\n",
    "            \"Family_Size\",\n",
    "            \"Age\",\n",
    "            \"Work_Experience\",\n",
    "            \"Income_Per_Family\",\n",
    "            \"Age_Experience_Interaction\"\n",
    "        ]\n",
    "        input_df = input_df[expected_columns]  # Reorder columns to match expected order\n",
    "\n",
    "        # Validate data types\n",
    "        expected_dtypes = {\n",
    "            \"Annual_Income\": \"int64\",\n",
    "            \"Family_Size\": \"int64\",\n",
    "            \"Age\": \"int64\",\n",
    "            \"Work_Experience\": \"int64\",\n",
    "            \"Income_Per_Family\": \"float64\",\n",
    "            \"Age_Experience_Interaction\": \"int64\"\n",
    "        }\n",
    "\n",
    "        # Check if data types match the expected ones\n",
    "        for column, dtype in expected_dtypes.items():\n",
    "            if input_df[column].dtypes != dtype:\n",
    "                raise ValueError(f\"Data type mismatch for column '{column}'. Expected: {dtype}, Got: {input_df[column].dtypes}\")\n",
    "\n",
    "        # Pass the DataFrame to the model pipeline\n",
    "        prediction = model.predict(input_df)\n",
    "\n",
    "        return {\"prediction\": int(prediction[0])}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
